# Overview
We currently record candidate sessions by capturing DOM mutations and screenshots for integrity checks. However, this approach has led to performance issues across project questions.
To address this, we propose introducing full screen recording, which would:
- Improve session replay performance and provide a complete view for recruiters.
- Enable more comprehensive integrity verification using video streams.
- Allow consolidation of all integrity-related checks under a central service for easier management and scalability.

## Objectives
- **Records and streams the candidate’s screen** to HackerRank downstream services in a **highly performant** manner.
- **Supports near real-time integrity analysis** — frames should be consumable as soon as they are available, enabling integrity checks to complete within minutes after an attempt ends.
- **Provides a seamless playback experience** through a compatible player supporting:
    - `PLAY`
    - `SEEK_FORWARD_{SPEED}`
    - `SEEK_BACKWARD_{SPEED}`
    - Rendering of integrity events on the timeline.
- **Focuses initially on storage only** — recordings will be stored (e.g., on S3) without immediate analysis. During this phase, both **screenshots and screen recordings** will be uploaded for continuity.

## Engineering
There are two ways to approach this problem, either we create/augment integrity-events-service to be a full fledged proctoring + playback service or we have two independent services which will be responsible for their individual tasks - one for proctoring and one for playback. 

### IES as Full fledged Proctoring + Recording solution
- This approach modifies the existing IES service as proctoring service.
- It'll be responsible for managing the session recording -> generating playlist, processing video/image streams etc. 
- It'll also be responsible for doing all proctoring related things, webcam analysis, screenshot analysis, inserting proctoring events in cassandra etc. 
- Currently, IES, though decoupled, has no concept of a session. We interact with the API's via `attempt_type, attempt_id`. We'll have to introduce a new set of v2 APIs that provide a session object against which we'll interact with. A new DB (mySQL) would be required here.

### IES as proctoring + Session Replay as recorder solution
- This approach keeps the recording aspect decoupled from proctoring approach. Any service (including IES) can consume assets generated by session replay service as part of their workflow. 
- SRS will have the following responsibilities
	- asset upload of webcam/screenshare (possibly dual camera feed in case we wanna make it)
	- stitch the video feed, fill in the missing videos data with placeholder images.
	- create consumable HLS playlist
	- generate thumbnails
	- take care of archivable + deletion policies
	- Send further events so other services can take on the responsibilities
- Requires the least changes on our current infrastructure while having the modularity to add more features on top of it. 

For now, we'll focus on the 2nd approach more in this document, if we want to go with 1st approach, not much will change in the design and implementation docs, SRS would act as a proxy for IES for the time being.
# Architecture
Lets deep dive in the new SRS flows -

We have three broad flows to engineer -
- **Session Recording**: We need backend to provide support for enabling screen recording on frontend side. 
- **Session Processing**: We need to process the session recording (creating a playable link, extracting screenshots for ss analysis, creating thumbnails etc). This will also extend to webcam recordings.
- **Session Playback**: We need to be able to playback the session while having support for the previous version of session recorder. 

Every session will be represented by a unique `session_uuid` on the integrity events service. We'll need to create a new MYSQL DB on integrity-events-service for facilitating this and storing (product_type, product_id) mapping vs a unique `session_uuid`.
## Storage
```
# RAW Files
/proctor/ies/<session_uuid>/<asset_name>/raw/
	- [Individual webM chunks]

# Processed Files
/proctor/ies/<session_uuid>/<asset_name>/processed/
	- hls_playlist
	 ├── master.m3u8
	 ├── index_360p.m3u8
	 ├── index_480p.m3u8
	 ├── index_720p.m3u8
	 ├── 720p/
	 ├── 360p/
	 ├── 480p/
	- frames
	- frame_thumbnails
	- stitched_video
	- playlist_cache
```


Let's deep dive into the individual layers 
### Session Recording
![[Integrity Session Recording]]

### Processing
- We'll utilize a single SQS queue to trigger backend processing of the session.
- Proctoring is serially dependent on completion of SRS service results (frames of screenshare stream or webcam stream or finalized audio from webcam stream), hence it makes sense to have the first layer as SQS instead of kafka
- For initial version, we dont need a kafka or event bus as we'll only be storing the raw videos and not doing any significant post processing on this.
- We'll be having a fleet of consumers that will be listening to Kafka for processing different events in parallel.

![[Integrity Session Processing]]

### Playback
![[Integrity Session Playback]]

# Backend Contracts

## Session Replay Service
Currently, we have a misplaced URL mapping of events and session (should be reversed). We should either create the new APIs for these in the same v1 group or create new urls in v2 group with updated resource mapping.

### 1. POST /srs/api/v1/events/session
Creates a session on service side.  
Supports two replay versions: 
- dom_record 
- full_screen_record
#### Payload
```json
{
	product_type: <string>,
	product_id: <int>,
	replay_version: <enum> // dom_record, full_screen_record
}
```
#### Response
```json
{
	session_id: <uuid>,
	replay_version: <enum> // dom_record, full_screen_record
}
```

### 2. GET /srs/api/v1/events/session
Returns the session metadata required by the player, Will also return the version of player that should be used for playback. Response will differ basis the version used. Supports fetch by both (session_id) and (product_type, product_id)
#### Payload
```json
{
	session_id: <uuid?>,
	product_type: <string?>,
	product_id: <string?>
}
```
#### Response
This will be varied basis the version of the recorder.
```json
// for dom_record
{
	version: "dom_record",
	first_event_timestamp: <timestamp>,
	last_event_timestamp: <timestamp>,
	metadata: [<MeatdataObject>],
}

// for full_screen_record
{
	version: "full_screen_record",
	playback_url: <string>,
	playback_type: <enum> // fullvideo, hls_masterplaylist
}
```

### 3. GET /srs/api/v1/events/session/presigned-policy
Returns the signed policy for facilitating frontend s3 upload. Supports fetch by both (session_id) and (product_type, product_id)
#### Payload
```json
{
	session_id: <uuid?>,
	product_type: <string?>,
	product_id: <string?>
}
```
#### Response
```json
{
	"postFields": {
		"Content-Type": "image/jpg",
		"acl": "private",
		"key":"proctor/screenshare_stream/screen_attempt/test1280x720/raw/",
		"policy": "eyJjb2..",
		"x-amz-algorithm": "AWS4-HMAC-SHA256",
		"x-amz-credential": "ASIAY/20251117/us-east-1/s3/aws4_request",
		"x-amz-date": "20251117T064827Z",
		"x-amz-security-token": "IQoJb3JpZ2lu...",
		"x-amz-signature": "cf396668906e50e893e416b...e"
	},
	"url": "https://hr-preprod-istreet-proctor.s3.us-east-1.amazonaws.com"
}
```

### 4. POST /srs/api/v1/events/session/playback
Starts processing of the session playback 
#### Payload
```json
{
	session_id: <uuid?>,
	product_type: <string?>,
	product_id: <string?>
}
```
#### Response
`HEAD OK`

### SRS SQS Consumer
- This consumer will listen to the SQS and do simple post-processing of the video.
- This consumer is also responsible for creating the HLS playlist. Since, for now, we'll be doing this post the test is ended, this consumer can only do HLS playlist generation. 
- For screen-recordings that are missing chunks, we’ll replace them with a placeholder segment video (black screen) to not break continuity.
- 
## Technical Considerations

- We need to sync the user’s clock with server clock as part of system check screens. We saw one ticket wrt user setting his clock something else from standard internet time. This can mess up screen-recording timestamps if user changes his clock midway during the test.
- If we want to be able to read in almost realtime for integrity events analysis, we’ll have to ensure the videos we upload to s3 are self contained webm files. If we upload the continuous streams, we can only playback the video once the attempt has ended or we’ll have to continuously keep replaying the video stream from the beginning.



# Reviews
- [ ] Integrity Service as whole should be pursued instead of having different services
- [ ] session_uuid should be primary key


